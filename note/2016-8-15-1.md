This paper indroduce a dropout trick for convolution neural networks.

- Tranditional dropout was added in the fully connected layer
- Dropout was add after convolution and before max-pooling

![fig1](https://cloud.githubusercontent.com/assets/7859276/17664121/6840abc8-6324-11e6-93df-7f6f8db352d4.png "maxpooling-dropout")

- some results:

![fig2](https://cloud.githubusercontent.com/assets/7859276/17664185/dea1e5d4-6324-11e6-8e18-13059e0a1c5f.png "results")
