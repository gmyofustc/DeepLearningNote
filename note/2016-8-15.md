This Paper indroduce a new dropout trick for rnn networks. 

- Trandition dropout for rnn network can only add the dropout before or after rnn networks.
- If add dropout in inner recurrent layer, the result will be very bad
- The paper add dropout in the inner recurrent layer, and the trick is fix the dropout mask

![alt text](https://cloud.githubusercontent.com/assets/7859276/17663696/ff7ce924-6320-11e6-9c96-9ecaad204597.png "Dropout Trick")

